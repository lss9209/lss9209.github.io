---
title: "ElasticSearch의 색인과 분석 성능 최적화(향상) 시키기"
date: 2021-03-13 10:01:47 -0400
categories: ElasticSearch
---
# 1. 엘라스틱서치에서 색인 성능 향상

## 1 정적 매핑 활용하기
동적 매핑은 물론 ES의 유연성을 증가시켜주는 장점 중 하나이지만 데이터가 문자열인 필드를 동적으로 생성할때 자동으로 ES는 이 문자열 필드의 타입을 'text'와 'keyword'로 이중으로 매핑한다. 이때 이중 매핑이 성능을 저하시키는 역할을 할 수 있으므로 정적으로 스키마를 주어서 특정 필드는 오로지 'text'에만 매핑된다던지 하게 하면 성능을 향상시킬 수 있다. <br>

## 2 _all 필드 비활성화
ES 5.x버전 이하에만 해당되고 ES 6.x 이상의 유저는 신경쓸 부분이 아니다.(ES 6버전부터 _all 필드 사라짐) 5버전 이하의 사용자는 따로 검색해보길 바란다.

## 3 refresh_interval 변경 활용하기
refresh를 통해 메모리 버퍼캐시에 있던 문서들이 실제 디스크의 세그먼트에 저장된다. 원래 이 과정은 일정 텀을 미리 설정해두고 그 텀마다 주기적으로 진행된다.<br>
refresh가 되지 않은 문서는 검색이 되지 않기 때문에 색인과 동시에 검색을 요하는 문서는 이렇게 자주 refresh를 해줘야 한다. 그러나 이런 사례를 생각해보자.<br>
"색인을 폭발적으로 해야하는 상황(이를테면 데이터 마이그레이션)인데 색인하는 동안에는 검색요청이 없을 예정인 상황"<br>
이렇다면 이 때 refresh주기를 기본값이 1초로 하게되면 가뜩이나 마이그레이션으로 색인이 많은 성능을 잡아먹는데 거기다 Disk IO에 해당하여 성능 잡아먹는 도둑인 refresh까지 이루어지게 된다. 그래서 성능이 많이 떨어질 수 있다.<br>
따라서 이 경우에 마이그레이션 중에는 refresh를 아예 꺼주고 마이그레이션 완료 후에 다시 refresh를 켜주는 식으로 운용하면 성능적 이득을 많이 볼 수 있다.<br>

## 4 bulk API 활용하기
bulk API는 일일히 json형태로 명령들을 나열하여 작성할 수도 있고 그런 명령들을 따로 파일로 작성해서 뺴둔 뒤 --data-binary @파일명.json으로 파일에서 bulk 명령어를 읽어 올 수도 있다.<br>
어느쪽이든 간에 Bulk API를 사용한 쪽은 그 bulk API에 포함된 명령들을 단건단건 날리는 쪽에 비해 월등한 성능향상 (대략 1만건을 단건처리시 2분걸리는 거를 1만건을 bulk로 처리시 1초 소요)을 기대할 수 있다.<br>

# 2. 엘라스틱서치에서 검색 성능 향상

## 1. 캐시를 최대한 활용하기
ES는 node query cache, Shard request cache, Field data cache와 같은 캐시들을 활용한다.<br>
node query cache는 노드단위에서 문서째로 캐싱하고 Shard request cache는 샤드단위로 집계결과등을 캐싱한다. 마지막으로 Field data cache는 특정 필드에 대한 검색 및 통계질의를 했을 때 한 필드의 데이터들을 캐시한다<br>
이런 캐시설정들을 디폴트로 잘 되어있나 요지는 "오직 필터계열의 검색만이 캐시를 활용한다는 점이다." 따라서 검색쿼리를 구성할 때 가급적 필터로만 처리해도 되는 부분들은 철저히 필터로 검색하는 것이 성능확보에 중요하다.<br>
가령, 단순한 term검색으로 처리해도 될 부분에 query의 match를 쓴다면 스코어계산과는 별도로 캐시활용의 측면에서도 손해보는 쿼리를 날린 꼴이 되는 것이다.<br>

## 2. copy_to 활용
"first_name": "sangseung", "last_name": "lee"인 문서를 검색하려면 매치쿼리를 각각에 맞게 두번 날려야 한다. 하지만 properties 세팅을 통해 first_name필드와 last_name필드에 "copy_to" : "full_name"과 같이 copy_to를 주고 별도의 "full_name" 필드를 추가하면 "full_name" : "sangseung lee"와 같이 매치쿼리 한번으로 검색을 할 수 있다.<br>
즉, copy_to는 여러 필드를 묶어주어 매치쿼리 여러번 날릴 것을 한 번 날리게끔 해주는 기능이다.

## 3. 샤드 배치 최적화
공식적으로 프라이머리 샤드의 갯수는 현재 클러스터를 구성하고 있는 노드의 갯수와 앞으로 몇개가 증설되어 미래의 클러스터를 구성하고 있을 노드의 총 갯수의 최소공배수로 해 주는 것이 좋다!<br>
가령 지금 3대가 클러스터를 이루고 있으나 한대 더 추가될 예정이면 미래의 클러스터의 노드 수는 3 + 1 = 4개이다. 그러면 프라이머리 샤드 갯수는 3과 4의 최소공배수인 12로 해주면 모든 노드가 볼륨 사용량이 균형을 이루며 골고루 색인/검색에 참여하게 된다.<br>
이제 레플리카 샤드의 최적의 갯수를 살펴보자.<br>
레플리카 샤드의 갯수는 많으면 많을수록 검색 성능에 유리하다. 그러나 레플리카 샤드를 많이 늘리면 늘릴수록 두가지 측면에서 손해를 본다.<br>
첫째로, 색인 성능이 손해를 본다. 그 많은 레플리카 샤드들에도 값을 색인해야 하기 때문이다.
둘째로, 마스터노드의 부하가 커진다. 마스터노드가 관리해야하는 샤드의 갯수가 많아짐에 따라 관리할 메타데이터가 증가되기 때문이다. 따라서 경우에 따라서는 데이터노드의 부하는 없는데 마스터노드에만 과부하가 걸려 전체 클러스터의 성능이 손해로 이어질 수도 있다.<br>

## 4. forcemerge API
ES는 백그라운드에서 자동으로 세그먼트 병합(merge)을 진행하고 있으나 필요에 따라 사용자가 인위적으로 Forcemerge API를 주어 세그먼트를 병합시킬 수 있다.<br>
세그먼트가 적을 수록 Disk IO 발생횟수가 적을 것이므로 어찌됐든 세그먼트는 적은 수로 병합되는 방향이 바람직하다.<br>
보통 색인이 일정기간 이루어지고 공식적으로 앞으로 색인이 이루어지지 않을 인덱스는 마지막에 forceMerge APi를 통해 최종 세그먼트 병합을 해준다. 그리고 readOnly로 처리하여 추가색인을 막음으로써 추가적인 세그먼트의 발생자체도 같이 막아버린다. 그 외의 일반적인 인덱스는 디폴트로 백그라운드에서 이루어지는 세그먼트 병합의 효과를 누리면 된다.

